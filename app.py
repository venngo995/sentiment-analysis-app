
import streamlit as st
import nltk
from nltk.corpus import movie_reviews
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import random

nltk.download('movie_reviews')

@st.cache_data
def load_data():
    documents = [(list(movie_reviews.words(fileid)), category)
                 for category in movie_reviews.categories()
                 for fileid in movie_reviews.fileids(category)]
    random.shuffle(documents)
    texts = [" ".join(words) for words, label in documents]
    labels = [1 if label == "pos" else 0 for words, label in documents]
    return texts, labels

@st.cache_resource
def train_model(texts, labels):
    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
    X_vec = vectorizer.fit_transform(texts)
    model = LogisticRegression()
    model.fit(X_vec, labels)
    return model, vectorizer

def run_prediction(text, model, vectorizer):
    user_vec = vectorizer.transform([text])
    prediction = model.predict(user_vec)[0]
    proba = model.predict_proba(user_vec)[0]
    label = "T√çCH C·ª∞C üòÑ" if prediction == 1 else "TI√äU C·ª∞C üò†"
    st.subheader(f"K·∫øt qu·∫£: {label}")
    st.write(f"X√°c su·∫•t t√≠ch c·ª±c: `{proba[1]:.2f}`, ti√™u c·ª±c: `{proba[0]:.2f}`")

def main():
    st.title("üé≠ Ph√¢n t√≠ch c·∫£m x√∫c b√¨nh lu·∫≠n phim (IMDb)")
    st.write("Nh·∫≠p m·ªôt ƒëo·∫°n vƒÉn/b√¨nh lu·∫≠n v√† h·ªá th·ªëng s·∫Ω ph√¢n lo·∫°i l√† t√≠ch c·ª±c ho·∫∑c ti√™u c·ª±c.")

    texts, labels = load_data()
    model, vectorizer = train_model(texts, labels)

    user_input = st.text_area("‚úçÔ∏è Nh·∫≠p n·ªôi dung b√¨nh lu·∫≠n:")

    if st.button("Ph√¢n t√≠ch"):
        if user_input.strip() == "":
            st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung ƒë·ªÉ ph√¢n t√≠ch.")
        else:
            run_prediction(user_input, model, vectorizer)

if __name__ == "__main__":
    main()
